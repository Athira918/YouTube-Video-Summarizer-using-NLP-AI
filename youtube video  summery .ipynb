{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be597240-4fbf-4dc9-b52d-3219555e5b49",
   "metadata": {},
   "source": [
    "## Step 1: Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1fd7a-7922-4656-b225-1748a436afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pytube\n",
    "import youtube_transcript_api\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from heapq import nlargest\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import textwrap\n",
    "from colorama import Fore, Back, Style, init\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26738db1-4fd3-4136-b1b8-4e4a2cd5817f",
   "metadata": {},
   "source": [
    "TfidfVectorizer: Converts text into a matrix of TF-IDF features.\n",
    "\n",
    "YouTubeTranscriptApi: Fetches subtitles/transcripts from a YouTube video.\n",
    "\n",
    "nltk: For natural language processing (tokenization, stopwords, etc.).\n",
    "\n",
    "re: For regular expressions (text cleaning).\n",
    "\n",
    "numpy: For numerical operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdca0b07-b2e1-4a2b-a68b-1e295f9b26b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "init(autoreset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a46cbdd-839c-4d19-bb93-3fbd92339d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8839c701-6467-4fde-8a5d-f388c2b73ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"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\", # Add your OpenRouter API key here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3f5b39-c508-482d-93b2-203c96d5e1ac",
   "metadata": {},
   "source": [
    "# Step 2:Extracting YouTube Video IDs from Various URL Formats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e4b27f9-9dcc-4196-bdcc-bffe3a5554e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(youtube_url):\n",
    "    \"\"\"Extract the video ID from a YouTube URL.\"\"\"\n",
    "    parsed_url = urlparse(youtube_url)\n",
    "    \n",
    "    if parsed_url.netloc == 'youtu.be':\n",
    "        return parsed_url.path[1:]\n",
    "    \n",
    "    if parsed_url.netloc in ('www.youtube.com', 'youtube.com'):\n",
    "        if parsed_url.path == '/watch':\n",
    "            return parse_qs(parsed_url.query)['v'][0]\n",
    "        elif parsed_url.path.startswith('/embed/'):\n",
    "            return parsed_url.path.split('/')[2]\n",
    "        elif parsed_url.path.startswith('/v/'):\n",
    "            return parsed_url.path.split('/')[2]\n",
    "    \n",
    "    # If no match found\n",
    "    raise ValueError(f\"Could not extract video ID from URL: {youtube_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9cfeb-c17a-4570-a906-5831905b65e0",
   "metadata": {},
   "source": [
    "# Step 3: Retrieving and Combining the Transcript Text from a YouTube Video ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecdd48e3-0012-4a36-92cb-987dbf0ad4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(video_id):\n",
    "    \"\"\"Get the transcript of a YouTube video.\"\"\"\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        return ' '.join([entry['text'] for entry in transcript])\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving transcript: {str(e)}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d8f72-a9dc-4f41-8b6e-ec4c1f9f7021",
   "metadata": {},
   "source": [
    "# Step 4: Extractive Text Summarization Using Frequency-Based Scoring with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a4c845d-4755-4116-b2bb-7cc66cd26007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text_nltk(text, num_sentences=5):\n",
    "    \"\"\"Summarize text using frequency-based extractive summarization with NLTK.\"\"\"\n",
    "    if not text or text.startswith(\"Error\") or text.startswith(\"Transcript not available\"):\n",
    "        return text\n",
    "    \n",
    "    # Tokenize the text into sentences and words\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # If there are fewer sentences than requested, return all sentences\n",
    "    if len(sentences) <= num_sentences:\n",
    "        return text\n",
    "    \n",
    "    # Tokenize words and remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # Calculate word frequencies\n",
    "    freq = FreqDist(words)\n",
    "    \n",
    "    # Score sentences based on word frequencies\n",
    "    sentence_scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in word_tokenize(sentence.lower()):\n",
    "            if word in freq:\n",
    "                if i in sentence_scores:\n",
    "                    sentence_scores[i] += freq[word]\n",
    "                else:\n",
    "                    sentence_scores[i] = freq[word]\n",
    "    \n",
    "    # Get the top N sentences with highest scores\n",
    "    summary_sentences_indices = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    summary_sentences_indices.sort()  # Sort to maintain original order\n",
    "    \n",
    "    # Construct the summary\n",
    "    summary = ' '.join([sentences[i] for i in summary_sentences_indices])\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea6f3d-b1f1-4359-9ae5-32f1b9ecace8",
   "metadata": {},
   "source": [
    "# Step 5: Generating AI-Powered Summaries Using the Mistral Model via OpenRouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d59ef3-4bce-4d10-a6a9-f9ef0f827de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text_ai(text, video_title, num_sentences=5):\n",
    "    \"\"\"Summarize text using the Mistral AI model via OpenRouter.\"\"\"\n",
    "    if not text or text.startswith(\"Error\") or text.startswith(\"Transcript not available\"):\n",
    "        return text\n",
    "    \n",
    "    # Truncate text if it's too long (models often have token limits)\n",
    "    max_chars = 15000  # Adjust based on model's context window\n",
    "    truncated_text = text[:max_chars] if len(text) > max_chars else text\n",
    "    \n",
    "    prompt = f\"\"\"Please provide a concise summary of the following YouTube video transcript.\n",
    "Title: {video_title}\n",
    "\n",
    "Transcript:\n",
    "{truncated_text}\n",
    "\n",
    "Create a clear, informative summary that captures the main points and key insights from the video.\n",
    "Your summary should be approximately {num_sentences} sentences long.\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error generating AI summary: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976a507-f824-4b2d-b7d0-67fd00839c61",
   "metadata": {},
   "source": [
    "# Step 6: End-to-End YouTube Video Summarization — Extracting ID, Retrieving Transcript, and Generating Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "983d7ee7-a951-4a60-968c-75c554cb704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_youtube_video(youtube_url, num_sentences=5):\n",
    "    \"\"\"Main function to summarize a YouTube video's transcription.\"\"\"\n",
    "    try:\n",
    "        video_id = extract_video_id(youtube_url)\n",
    "        transcript = get_transcript(video_id)\n",
    "        \n",
    "        # Get video title for context\n",
    "        try:\n",
    "            yt = pytube.YouTube(youtube_url)\n",
    "            video_title = yt.title\n",
    "            \n",
    "        except Exception as e:\n",
    "            video_title = \"Unknown Title\"\n",
    "\n",
    "        \n",
    "        # Generate both summaries\n",
    "        print(Fore.YELLOW + f\"Generating AI summary with {num_sentences} sentences...\")\n",
    "        ai_summary = summarize_text_ai(transcript, video_title, num_sentences)\n",
    "        \n",
    "        print(Fore.YELLOW + f\"Generating NLTK summary with {num_sentences} sentences...\")\n",
    "        nltk_summary = summarize_text_nltk(transcript, num_sentences)\n",
    "        \n",
    "        return {\n",
    "            \"video_title\": video_title,\n",
    "            \"video_id\": video_id,\n",
    "            \"ai_summary\": ai_summary,\n",
    "            \"nltk_summary\": nltk_summary,\n",
    "            \"full_transcript_length\": len(transcript.split()),\n",
    "            \"nltk_summary_length\": len(nltk_summary.split()),\n",
    "            \"ai_summary_length\": len(ai_summary.split()) if not ai_summary.startswith(\"Error\") else 0\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"Convert seconds to a readable time format.\"\"\"\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    if hours > 0:\n",
    "        return f\"{hours}h {minutes}m {seconds}s\"\n",
    "    elif minutes > 0:\n",
    "        return f\"{minutes}m {seconds}s\"\n",
    "    else:\n",
    "        return f\"{seconds}s\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a9b3fe-4bc0-4968-aac5-32f922cbb101",
   "metadata": {},
   "source": [
    "# Step 7: Formatting Large Numbers for Improved Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "146651a2-9e2d-41d0-9258-6de106b7aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_number(number):\n",
    "    \"\"\"Format large numbers with commas for readability.\"\"\"\n",
    "    return \"{:,}\".format(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda101c-91b2-4a8c-ae05-ca0d8e75f207",
   "metadata": {},
   "source": [
    "# Step 8: Displaying Text in a Styled Box with Optional Title and Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c2ece27-06b2-41f1-9bf3-568832d78990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_boxed_text(text, width=80, title=None, color=Fore.WHITE):\n",
    "    \"\"\"Print text in a nice box with optional title.\"\"\"\n",
    "    wrapper = textwrap.TextWrapper(width=width-4)  # -4 for the box margins\n",
    "    wrapped_text = wrapper.fill(text)\n",
    "    lines = wrapped_text.split('\\n')\n",
    "    \n",
    "    # Print top border with optional title\n",
    "    if title:\n",
    "        title_space = width - 4 - len(title)\n",
    "        left_padding = title_space // 2\n",
    "        right_padding = title_space - left_padding\n",
    "        print(color + '┌' + '─' * left_padding + title + '─' * right_padding + '┐')\n",
    "    else:\n",
    "        print(color + '┌' + '─' * (width-2) + '┐')\n",
    "    \n",
    "    # Print content\n",
    "    for line in lines:\n",
    "        padding = width - 2 - len(line)\n",
    "        print(color + '│ ' + line + ' ' * padding + '│')\n",
    "    \n",
    "    # Print bottom border\n",
    "    print(color + '└' + '─' * (width-2) + '┘')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2010d9c0-86d3-4534-b299-71d655ed636e",
   "metadata": {},
   "source": [
    "# Final Step: Running the YouTube Video Summarizer and Displaying Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6c6b8-425f-46c3-ab7c-6cf969b46977",
   "metadata": {},
   "source": [
    "This final step integrates all previous components—prompting the user for a YouTube URL and desired summary length, processing the video, and then printing well-formatted AI and NLTK summaries along with key metadata in a visually styled terminal output. It serves as the main entry point of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce3e5c75-17ec-431d-889a-0f01ed6f6f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "                                                YOUTUBE VIDEO SUMMARIZER                                                \n",
      "========================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32mEnter YouTube video URL: \u001b[37m https://youtu.be/Dqw_ykwmC_o\n",
      "\u001b[32mEnter number of sentences for summaries (default 5): \u001b[37m 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching and analyzing video transcript... Please wait...\n",
      "\n",
      "Generating AI summary with 10 sentences...\n",
      "Generating NLTK summary with 10 sentences...\n",
      "\n",
      "========================================================================================================================\n",
      "                                                     Unknown Title                                                      \n",
      "========================================================================================================================\n",
      "\n",
      "                                                   VIDEO INFORMATION                                                    \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Video ID: Dqw_ykwmC_o                                               URL: https://youtu.be/Dqw_ykwmC_o\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "                                 AI SUMMARY (222 words, condensed 89% from 1983 words)                                  \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  The video titled \"Good Bye Ghost\" details the antics of a group planning to debunk ghost myths at a supposedly\n",
      "  haunted house in Aanakkuzhi. The group, including a sibling duo, is faced with humorous but tense moments as they\n",
      "  banter and navigate the supposed ghostly locale. The siblings are involved in a YouTube channel called \"Ghost\n",
      "  Debugging,\" where they mock ghost stories and debunk myths.\n",
      "\n",
      "  A crucial part of the narrative revolves around the siblings accepting a job to stay in a purportedly haunted\n",
      "  house for seven days, posting daily videos claiming there are no ghosts, in exchange for 10 lakhs rupees. Their\n",
      "  decision comes with ethical dilemmas and family tensions, particularly with their sister who doubts the job's\n",
      "  integrity. The premise highlights the financial struggles they face, including family expectations and debt.\n",
      "  During their stay in the haunted house, they encounter a dead body, which complicates their mission and puts them\n",
      "  in dire straits. The initial humor turns into a serious quandary as they grapple with the legal and ethical\n",
      "  implications of their situation. They must decide whether to call the police and risk exposing their scheme or\n",
      "  figure out how to handle the dilemma themselves. Despite the challenges, the group ultimately aims to unravel the\n",
      "  mystery to prove the house is free of supernatural elements and secure the promised payment.\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "                                NLTK SUMMARY (126 words, condensed 94% from 1983 words)                                 \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  Listen, let me tell you one thing first.. I’m doing today’s intro.\n",
      "\n",
      "  If one of us slips, people might say a ghost pushed us! But someone said he’d pay us to say the house is haunted.\n",
      "\n",
      "  You have your sister's matter and house, she has a house to make. Then post a video on Day 8 saying the house is\n",
      "  haunted.\n",
      "\n",
      "  This is the key to the house.. if my deal sounds good to you..\n",
      "\n",
      "  10 lakh rupees for staying in a house for 7 days? No one's gonna hand over that kind of money without a reason.\n",
      "\n",
      "  Let’s see who looks mad after 7 days! Let’s see who looks mad after 7 days! No one's gonna hand over that kind of\n",
      "  money without a reason.\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_summary_result(result, width=80):\n",
    "    \"\"\"Print the summary result in a nicely formatted way.\"\"\"\n",
    "    if \"error\" in result:\n",
    "        print_boxed_text(f\"Error: {result['error']}\", width=width, title=\"ERROR\", color=Fore.RED)\n",
    "        return\n",
    "    \n",
    "    # Terminal width\n",
    "    terminal_width = width\n",
    "    \n",
    "    # Print header with video information\n",
    "    print(\"\\n\" + Fore.CYAN + \"=\" * terminal_width)\n",
    "    print(Fore.CYAN + Style.BRIGHT + result['video_title'].center(terminal_width))\n",
    "    print(Fore.CYAN + \"=\" * terminal_width + \"\\n\")\n",
    "    \n",
    "    # Video metadata section\n",
    "    print(Fore.YELLOW + Style.BRIGHT + \"VIDEO INFORMATION\".center(terminal_width))\n",
    "    print(Fore.YELLOW + \"─\" * terminal_width)\n",
    "    \n",
    "    # Two-column layout for metadata\n",
    "    col_width = terminal_width // 2 - 2\n",
    "    \n",
    "    # Row 3\n",
    "    print(f\"{Fore.GREEN}Video ID: {Fore.WHITE}{result['video_id']:<{col_width}}\"\n",
    "          f\"{Fore.GREEN}URL: {Fore.WHITE}https://youtu.be/{result['video_id']}\")\n",
    "    \n",
    "    print(Fore.YELLOW + \"─\" * terminal_width + \"\\n\")\n",
    "    \n",
    "    # AI Summary section\n",
    "    ai_compression = \"N/A\"\n",
    "    if result['ai_summary_length'] > 0:\n",
    "        ai_compression = round((1 - result['ai_summary_length'] / result['full_transcript_length']) * 100)\n",
    "    \n",
    "    ai_summary_title = f\" AI SUMMARY ({result['ai_summary_length']} words, condensed {ai_compression}% from {result['full_transcript_length']} words) \"\n",
    "    \n",
    "    print(Fore.GREEN + Style.BRIGHT + ai_summary_title.center(terminal_width))\n",
    "    print(Fore.GREEN + \"─\" * terminal_width)\n",
    "    \n",
    "    # Print the AI summary with proper wrapping\n",
    "    wrapper = textwrap.TextWrapper(width=terminal_width-4, \n",
    "                                  initial_indent='  ', \n",
    "                                  subsequent_indent='  ')\n",
    "    \n",
    "    # Split AI summary into paragraphs and print each\n",
    "    ai_paragraphs = result['ai_summary'].split('\\n')\n",
    "    for paragraph in ai_paragraphs:\n",
    "        if paragraph.strip():  # Skip empty paragraphs\n",
    "            print(wrapper.fill(paragraph))\n",
    "            print()  # Empty line between paragraphs\n",
    "    \n",
    "    print(Fore.GREEN + \"─\" * terminal_width + \"\\n\")\n",
    "    \n",
    "    # NLTK Summary section\n",
    "    nltk_compression = round((1 - result['nltk_summary_length'] / result['full_transcript_length']) * 100)\n",
    "    nltk_summary_title = f\" NLTK SUMMARY ({result['nltk_summary_length']} words, condensed {nltk_compression}% from {result['full_transcript_length']} words) \"\n",
    "    \n",
    "    print(Fore.MAGENTA + Style.BRIGHT + nltk_summary_title.center(terminal_width))\n",
    "    print(Fore.MAGENTA + \"─\" * terminal_width)\n",
    "    \n",
    "    # Split NLTK summary into paragraphs and wrap each\n",
    "    paragraphs = result['nltk_summary'].split('. ')\n",
    "    formatted_paragraphs = []\n",
    "    \n",
    "    current_paragraph = \"\"\n",
    "    for sentence in paragraphs:\n",
    "        if not sentence.endswith('.'):\n",
    "            sentence += '.'\n",
    "        \n",
    "        if len(current_paragraph) + len(sentence) + 1 <= 150:  # Arbitrary length for paragraph\n",
    "            current_paragraph += \" \" + sentence if current_paragraph else sentence\n",
    "        else:\n",
    "            if current_paragraph:\n",
    "                formatted_paragraphs.append(current_paragraph)\n",
    "            current_paragraph = sentence\n",
    "    \n",
    "    if current_paragraph:\n",
    "        formatted_paragraphs.append(current_paragraph)\n",
    "    \n",
    "    # Print each paragraph\n",
    "    for paragraph in formatted_paragraphs:\n",
    "        print(wrapper.fill(paragraph))\n",
    "        print()  # Empty line between paragraphs\n",
    "    \n",
    "    print(Fore.MAGENTA + \"─\" * terminal_width + \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get terminal width\n",
    "    try:\n",
    "        terminal_width = os.get_terminal_size().columns\n",
    "        # Limit width to reasonable range\n",
    "        terminal_width = max(80, min(terminal_width, 120))\n",
    "    except:\n",
    "        terminal_width = 80  # Default if can't determine\n",
    "    \n",
    "    # Print welcome banner\n",
    "    print(Fore.CYAN + Style.BRIGHT + \"\\n\" + \"=\" * terminal_width)\n",
    "    print(Fore.CYAN + Style.BRIGHT + \"YOUTUBE VIDEO SUMMARIZER\".center(terminal_width))\n",
    "    print(Fore.CYAN + Style.BRIGHT + \"=\" * terminal_width + \"\\n\")\n",
    "    \n",
    "    youtube_url = input(Fore.GREEN + \"Enter YouTube video URL: \" + Fore.WHITE)\n",
    "    \n",
    "    num_sentences_input = input(Fore.GREEN + \"Enter number of sentences for summaries (default 5): \" + Fore.WHITE)\n",
    "    num_sentences = int(num_sentences_input) if num_sentences_input.strip() else 5\n",
    "    \n",
    "    print(Fore.YELLOW + \"\\nFetching and analyzing video transcript... Please wait...\\n\")\n",
    "    \n",
    "    result = summarize_youtube_video(youtube_url, num_sentences)\n",
    "    print_summary_result(result, width=terminal_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1808b1-a56c-4552-9adf-15aaccbb0bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=https://youtu.be/Dqw_ykwmC_o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
